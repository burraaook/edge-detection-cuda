{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTg2JqYSL64f",
        "outputId": "1628b0de-11ef-4ec8-e857-48086ef66404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-2mtfrpln\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-2mtfrpln\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0d2ab99cccbbc682722e708515fe9c4cfc50185a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4716 sha256=75f6b0132ec5a9ef8eb665489580b9bfd50ed7141c78cb997eda6404e7fd5268\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-14jm1pfg/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwsSqTb7MDuR",
        "outputId": "0c7c8d4c-13a8-42b9-9d37-c64ae00186cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name convolution_with_shm.cu\n",
        "\n",
        "\n",
        "#include <iostream>\n",
        "#include <string>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define STB_IMAGE_IMPLEMENTATION\n",
        "#include \"stb_image.h\"\n",
        "\n",
        "#define STB_IMAGE_WRITE_IMPLEMENTATION\n",
        "#include \"stb_image_write.h\"\n",
        "\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "\n",
        "bool TEST_MODE = false;\n",
        "\n",
        "// dummy kernel that does nothing\n",
        "__global__ void warmupKernel(int *dummy) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    dummy[i] = 0;\n",
        "}\n",
        "\n",
        "// __constant__ float constantKernel[9];\n",
        "\n",
        "__global__ void convolutionKernel(const float *input, float *output, int width,\n",
        "                                    int height, const float *kernel, int kernelSize) {\n",
        "    int center = (kernelSize - 1) / 2;\n",
        "\n",
        "    // x is the column index, y is the row index\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    // fill kernel into shared memory\n",
        "    // if (threadIdx.x == 0 && threadIdx.y == 0) {\n",
        "    //     for (int i = 0; i < kernelSize * kernelSize; ++i) {\n",
        "    //         sharedKernel[i] = kernel[i];\n",
        "    //     }\n",
        "    // }\n",
        "\n",
        "    extern __shared__ float sharedKernel[];\n",
        "    int K2 = kernelSize * kernelSize;\n",
        "    if (threadIdx.x < K2) {\n",
        "        sharedKernel[threadIdx.x] = kernel[threadIdx.x];\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    if (x >= center && x < width - center && y >= center && y < height - center) {\n",
        "        float sum = 0.0;\n",
        "\n",
        "        // apply convolution\n",
        "        for (int ky = 0; ky < kernelSize; ++ky) {\n",
        "            for (int kx = 0; kx < kernelSize; ++kx) {\n",
        "                int imageX = x + kx - center;\n",
        "                int imageY = y + ky - center;\n",
        "\n",
        "                sum += input[imageY * width + imageX] * sharedKernel[ky * kernelSize + kx];\n",
        "            }\n",
        "        }\n",
        "        // set the output pixel value\n",
        "        output[y * width + x] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void applyLoGFilterCUDA(const float *input, float *output, int width, int height, int blockDimX,\n",
        "                        int blockDimY, int gridDimX, int gridDimY, int gridDimZ, int dim, float& milliseconds) {\n",
        "    // define the Laplacian of Gaussian (LoG) kernel\n",
        "    float kernel[9] = {\n",
        "        0, 1, 0,\n",
        "        1, -4, 1,\n",
        "        0, 1, 0\n",
        "    };\n",
        "    int kernelSize = 3;\n",
        "\n",
        "    // define 5x5 kernel\n",
        "    // float kernel[25] = {\n",
        "    //     0, 0, 1, 0, 0,\n",
        "    //     0, 1, 2, 1, 0,\n",
        "    //     1, 2, -16, 2, 1,\n",
        "    //     0, 1, 2, 1, 0,\n",
        "    //     0, 0, 1, 0, 0\n",
        "    // };\n",
        "    // int kernelSize = 5;\n",
        "\n",
        "    int threadsPerBlock = blockDimX * blockDimY;\n",
        "    if (threadsPerBlock > 1024) {\n",
        "        std::cerr << \"Error: The number of threads per block must be less than or equal to 1024.\" << std::endl;\n",
        "        milliseconds = -1.0f;\n",
        "        return;\n",
        "    }\n",
        "    // Allocate device memory\n",
        "    float *d_input, *d_output, *d_kernel;\n",
        "    gpuErrchk(cudaMalloc((void**)&d_input, width * height * sizeof(float)));\n",
        "    gpuErrchk(cudaMalloc((void**)&d_output, width * height * sizeof(float)));\n",
        "    gpuErrchk(cudaMalloc((void**)&d_kernel, kernelSize * kernelSize * sizeof(float)));\n",
        "\n",
        "    // Copy data from host to device\n",
        "    gpuErrchk(cudaMemcpy(d_input, input, width * height * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    gpuErrchk(cudaMemcpy(d_kernel, kernel, kernelSize * kernelSize * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    // Configure and launch the CUDA kernel with shared memory\n",
        "    dim3 blockDim(blockDimX, blockDimY);\n",
        "    dim3 gridDim(gridDimX, gridDimY, gridDimZ);\n",
        "    int sharedMemorySize = kernelSize * kernelSize * sizeof(float);\n",
        "\n",
        "    // copy kernel to constant memory\n",
        "    // cudaMemcpyToSymbol(constantKernel, kernel, 9 * sizeof(float));\n",
        "\n",
        "    // warmup kernel\n",
        "    int *dummy;\n",
        "    cudaMalloc((void**)&dummy, width * height * sizeof(int));\n",
        "    warmupKernel<<<gridDim, blockDim>>>(dummy);\n",
        "    cudaFree(dummy);\n",
        "\n",
        "    // create cuda event for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // print number of thread in each block\n",
        "    std::cout << \"blockDimX: \" << blockDimX << std::endl;\n",
        "    std::cout << \"blockDimY: \" << blockDimY << std::endl;\n",
        "    std::cout << \"gridDimX: \" << gridDimX << std::endl;\n",
        "    std::cout << \"gridDimY: \" << gridDimY << std::endl;\n",
        "    std::cout << \"gridDimZ: \" << gridDimZ << std::endl;\n",
        "    std::cout << \"number of threads in each block: \" << blockDimX * blockDimY << std::endl;\n",
        "    std::cout << \"total number of blocks: \" << gridDimX * gridDimY * gridDimZ << std::endl;\n",
        "    std::cout << \"total number of threads: \" << gridDimX * gridDimY * gridDimZ * blockDimX * blockDimY << std::endl;\n",
        "\n",
        "    // start timing\n",
        "    cudaEventRecord(start);\n",
        "    convolutionKernel<<<gridDim, blockDim, sharedMemorySize>>>(d_input, d_output, width, height, d_kernel, kernelSize);\n",
        "    gpuErrchk(cudaPeekAtLastError());\n",
        "    gpuErrchk(cudaDeviceSynchronize());\n",
        "\n",
        "    // stop timing\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    std::cout << \"time taken: \" << milliseconds << \" ms\" << std::endl;\n",
        "\n",
        "    // copy the result back to the host\n",
        "    cudaMemcpy(output, d_output, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // free device memory\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "    cudaFree(d_kernel);\n",
        "\n",
        "    // destroy CUDA event\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "void configure_grid_2D(int width, int height, const int& blockDimX, const int& blockDimY, int& gridDimX, int& gridDimY, int& gridDimZ) {\n",
        "    gridDimX = (width + blockDimX - 1) / blockDimX;\n",
        "    gridDimY = (height + blockDimY - 1) / blockDimY;\n",
        "    gridDimZ = 1;\n",
        "}\n",
        "\n",
        "void saveOutputImagePNG(const float *outputImage, int width, int height, const std::string& filename) {\n",
        "    // create output image buffer\n",
        "    unsigned char *outputImageChar = new unsigned char[width * height];\n",
        "\n",
        "    // convert output to unsigned char\n",
        "    for (int i = 0; i < width * height; ++i) {\n",
        "        outputImageChar[i] = (unsigned char) std::round(outputImage[i] * 255.0f);\n",
        "    }\n",
        "\n",
        "    // Save the output image\n",
        "    stbi_write_png(filename.c_str(), width, height, 1, outputImageChar, 0);\n",
        "\n",
        "    delete[] outputImageChar;\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]) {\n",
        "\n",
        "    // ./program <input_image> <output_image> | ./program <input_image> <output_image> <-test>\n",
        "    if (argc != 3 && argc != 4) {\n",
        "        std::cerr << \"Usage: \" << argv[0] << \" input_image output_image\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "    else if (argc == 4 && std::string(argv[3]) != \"-test\") {\n",
        "        std::cerr << \"Usage: \" << argv[0] << \" input_image output_image\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    if (argc == 4) {\n",
        "        std::cout << \"Running in test mode.\" << std::endl;\n",
        "        TEST_MODE = true;\n",
        "    }\n",
        "\n",
        "    // Load input image\n",
        "    int width, height, channels;\n",
        "    unsigned char *inputImage = stbi_load(argv[1], &width, &height, &channels, 1);\n",
        "    float *outputImageFloat = new float[width * height];\n",
        "\n",
        "    if (!inputImage) {\n",
        "        std::cerr << \"Error loading image: \" << stbi_failure_reason() << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // print width and height\n",
        "    std::cout << \"width: \" << width << std::endl;\n",
        "    std::cout << \"height: \" << height << std::endl;\n",
        "\n",
        "    // convert input to float\n",
        "    float *inputImageFloat = new float[width * height];\n",
        "    for (int i = 0; i < width * height; ++i) {\n",
        "        inputImageFloat[i] = inputImage[i] / 255.0f;\n",
        "    }\n",
        "\n",
        "    if (TEST_MODE) {\n",
        "        int blockDimX;\n",
        "        int blockDimY;\n",
        "        int gridDimX, gridDimY, gridDimZ;\n",
        "        float milliseconds = 0.0f;\n",
        "\n",
        "        int fixedDimensionsX[9] = {32, 64, 128, 256, 512, 1024, 8, 16, 32};\n",
        "        int fixedDimensionsY[9] = {1, 1, 1, 1, 1, 1, 8, 16, 32};\n",
        "        int numFixedDimensions = 9;\n",
        "\n",
        "        // block combination array ex: 1 row as 1 block, 2 rows as 1 block, etc.\n",
        "        int blockDimXArray[6] = {width, width / 2, width / 4, width/2, width/4, 1};\n",
        "        int blockDimYArray[6] = {1, 1, 1, 2, 4, height};\n",
        "        int numBlockCombinations = 6;\n",
        "\n",
        "        // test fixed dimensions\n",
        "        for (int i = 0; i < numFixedDimensions; ++i) {\n",
        "            blockDimX = fixedDimensionsX[i];\n",
        "            blockDimY = fixedDimensionsY[i];\n",
        "            std::cout << std::endl << std::endl;\n",
        "\n",
        "            configure_grid_2D(width, height, blockDimX, blockDimY, gridDimX, gridDimY, gridDimZ);\n",
        "            std::string filename = \"output_2D_\" + std::to_string(blockDimX) + \"_\" + std::to_string(blockDimY) + \".png\";\n",
        "            applyLoGFilterCUDA(inputImageFloat, outputImageFloat, width, height, blockDimX, blockDimY, gridDimX, gridDimY, gridDimZ, 2, milliseconds);\n",
        "            saveOutputImagePNG(outputImageFloat, width, height, filename);\n",
        "        }\n",
        "\n",
        "        // test configurable dimensions\n",
        "        for (int i = 0; i < numBlockCombinations; ++i) {\n",
        "            blockDimX = blockDimXArray[i];\n",
        "            blockDimY = blockDimYArray[i];\n",
        "            std::cout << std::endl << std::endl;\n",
        "\n",
        "            configure_grid_2D(width, height, blockDimX, blockDimY, gridDimX, gridDimY, gridDimZ);\n",
        "\n",
        "            applyLoGFilterCUDA(inputImageFloat, outputImageFloat, width, height, blockDimX, blockDimY, gridDimX, gridDimY, gridDimZ, 2, milliseconds);\n",
        "            std::string filename = \"output_2D_\" + std::to_string(blockDimX) + \"_\" + std::to_string(blockDimY) + \".png\";\n",
        "            saveOutputImagePNG(outputImageFloat, width, height, filename);\n",
        "        }\n",
        "        return 0;\n",
        "    }\n",
        "\n",
        "    // apply Laplacian of Gaussian (LoG) filter using CUDA with shared memory\n",
        "\n",
        "    // one block per row\n",
        "    int blockDimX = width;\n",
        "    int blockDimY = 1;\n",
        "    int gridDimX, gridDimY, gridDimZ;\n",
        "\n",
        "    configure_grid_2D(width, height, blockDimX, blockDimY, gridDimX, gridDimY, gridDimZ);\n",
        "\n",
        "    float sum = 0.0f;\n",
        "    float milliseconds = 0.0f;\n",
        "    int count = 0;\n",
        "    for (int i = 0; i < 9; ++i) {\n",
        "        applyLoGFilterCUDA(inputImageFloat, outputImageFloat, width, height, blockDimX, blockDimY, gridDimX, gridDimY, gridDimZ, 2, milliseconds);\n",
        "        if (milliseconds != -1.0f) {\n",
        "            ++count;\n",
        "            sum += milliseconds;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    std::cout << \"average time taken: \" << sum / count << \" ms\" << std::endl;\n",
        "\n",
        "    saveOutputImagePNG(outputImageFloat, width, height, argv[2]);\n",
        "\n",
        "    // clean up\n",
        "    stbi_image_free(inputImage);\n",
        "    delete[] outputImageFloat;\n",
        "\n",
        "    std::cout << \"Laplacian of Gaussian (LoG) edge detection completed successfully.\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fd1PDrieTjdq",
        "outputId": "0700f8cd-066f-462f-9114-b0dad577f10e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/convolution_with_shm.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -o \"/content/src/convolution_with_shm.o\" /content/src/convolution_with_shm.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC0uzyyDTpCz",
        "outputId": "6f6b6d28-aefc-4915-d3e4-494bdced230d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(4275)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"old_limit\"\u001b[0m was set but never used\n",
            "     unsigned int cur, limit, old_limit;\n",
            "                              ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(5182)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"idata_limit_old\"\u001b[0m was set but never used\n",
            "                 stbi__uint32 idata_limit_old = idata_limit;\n",
            "                              ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(6969)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"out_size\"\u001b[0m was set but never used\n",
            "        int out_size = 0;\n",
            "            ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(6970)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"delays_size\"\u001b[0m was set but never used\n",
            "        int delays_size = 0;\n",
            "            ^\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/convolution_with_shm.o /content/src/image_03.png /content/src/conv_03.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTu8uAtWKPGV",
        "outputId": "2feb8400-3f7a-45a3-ab05-407e5037f336"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "width: 933\n",
            "height: 882\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.135456 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.104896 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.10624 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.104992 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.10448 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.105216 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.104768 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.106176 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.105024 ms\n",
            "average time taken: 0.108583 ms\n",
            "Laplacian of Gaussian (LoG) edge detection completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/convolution_with_shm.o /content/src/image_03.png /content/src/conv_03.png -test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNUdMM6aULGS",
        "outputId": "5d972906-507a-4c07-d4a7-a911d9c3bedb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in test mode.\n",
            "width: 933\n",
            "height: 882\n",
            "\n",
            "\n",
            "blockDimX: 32\n",
            "blockDimY: 1\n",
            "gridDimX: 30\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 32\n",
            "total number of blocks: 26460\n",
            "total number of threads: 846720\n",
            "time taken: 0.164288 ms\n",
            "\n",
            "\n",
            "blockDimX: 64\n",
            "blockDimY: 1\n",
            "gridDimX: 15\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 64\n",
            "total number of blocks: 13230\n",
            "total number of threads: 846720\n",
            "time taken: 0.09632 ms\n",
            "\n",
            "\n",
            "blockDimX: 128\n",
            "blockDimY: 1\n",
            "gridDimX: 8\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 128\n",
            "total number of blocks: 7056\n",
            "total number of threads: 903168\n",
            "time taken: 0.097952 ms\n",
            "\n",
            "\n",
            "blockDimX: 256\n",
            "blockDimY: 1\n",
            "gridDimX: 4\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 256\n",
            "total number of blocks: 3528\n",
            "total number of threads: 903168\n",
            "time taken: 0.099232 ms\n",
            "\n",
            "\n",
            "blockDimX: 512\n",
            "blockDimY: 1\n",
            "gridDimX: 2\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 512\n",
            "total number of blocks: 1764\n",
            "total number of threads: 903168\n",
            "time taken: 0.1024 ms\n",
            "\n",
            "\n",
            "blockDimX: 1024\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 1024\n",
            "total number of blocks: 882\n",
            "total number of threads: 903168\n",
            "time taken: 0.110592 ms\n",
            "\n",
            "\n",
            "blockDimX: 8\n",
            "blockDimY: 8\n",
            "gridDimX: 117\n",
            "gridDimY: 111\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 64\n",
            "total number of blocks: 12987\n",
            "total number of threads: 831168\n",
            "time taken: 0.131456 ms\n",
            "\n",
            "\n",
            "blockDimX: 16\n",
            "blockDimY: 16\n",
            "gridDimX: 59\n",
            "gridDimY: 56\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 256\n",
            "total number of blocks: 3304\n",
            "total number of threads: 845824\n",
            "time taken: 0.114336 ms\n",
            "\n",
            "\n",
            "blockDimX: 32\n",
            "blockDimY: 32\n",
            "gridDimX: 30\n",
            "gridDimY: 28\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 1024\n",
            "total number of blocks: 840\n",
            "total number of threads: 860160\n",
            "time taken: 0.114656 ms\n",
            "\n",
            "\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.107936 ms\n",
            "\n",
            "\n",
            "blockDimX: 466\n",
            "blockDimY: 1\n",
            "gridDimX: 3\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 466\n",
            "total number of blocks: 2646\n",
            "total number of threads: 1233036\n",
            "time taken: 0.11056 ms\n",
            "\n",
            "\n",
            "blockDimX: 233\n",
            "blockDimY: 1\n",
            "gridDimX: 5\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 233\n",
            "total number of blocks: 4410\n",
            "total number of threads: 1027530\n",
            "time taken: 0.105696 ms\n",
            "\n",
            "\n",
            "blockDimX: 466\n",
            "blockDimY: 2\n",
            "gridDimX: 3\n",
            "gridDimY: 441\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 932\n",
            "total number of blocks: 1323\n",
            "total number of threads: 1233036\n",
            "time taken: 0.11648 ms\n",
            "\n",
            "\n",
            "blockDimX: 233\n",
            "blockDimY: 4\n",
            "gridDimX: 5\n",
            "gridDimY: 221\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 932\n",
            "total number of blocks: 1105\n",
            "total number of threads: 1029860\n",
            "time taken: 0.114688 ms\n",
            "\n",
            "\n",
            "blockDimX: 1\n",
            "blockDimY: 882\n",
            "gridDimX: 933\n",
            "gridDimY: 1\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 882\n",
            "total number of blocks: 933\n",
            "total number of threads: 822906\n",
            "time taken: 0.68128 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name convolution_without_shm.cu\n",
        "\n",
        "\n",
        "#include <iostream>\n",
        "#include <string>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define STB_IMAGE_IMPLEMENTATION\n",
        "#include \"stb_image.h\"\n",
        "\n",
        "#define STB_IMAGE_WRITE_IMPLEMENTATION\n",
        "#include \"stb_image_write.h\"\n",
        "\n",
        "#define gpuErrchk(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
        "inline void gpuAssert(cudaError_t code, const char *file, int line, bool abort=true)\n",
        "{\n",
        "   if (code != cudaSuccess)\n",
        "   {\n",
        "      fprintf(stderr,\"GPUassert: %s %s %d\\n\", cudaGetErrorString(code), file, line);\n",
        "      if (abort) exit(code);\n",
        "   }\n",
        "}\n",
        "\n",
        "bool TEST_MODE = false;\n",
        "\n",
        "// dummy kernel that does nothing\n",
        "__global__ void warmupKernel(int *dummy) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    dummy[i] = 0;\n",
        "}\n",
        "\n",
        "__global__ void convolutionKernel(const float *input, float *output, int width,\n",
        "                                    int height, const float *kernel, int kernelSize) {\n",
        "    int center = (kernelSize - 1) / 2;\n",
        "\n",
        "    // x is the column index, y is the row index\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    // each thread writes which pixel it is processing\n",
        "    // printf(\"x: %d, y: %d\\n\", x, y);\n",
        "\n",
        "    if (x >= center && x < width - center && y >= center && y < height - center) {\n",
        "        float sum = 0.0;\n",
        "\n",
        "        // apply convolution using shared memory for the kernel\n",
        "        for (int ky = 0; ky < kernelSize; ++ky) {\n",
        "            for (int kx = 0; kx < kernelSize; ++kx) {\n",
        "                int imageX = x + kx - center;\n",
        "                int imageY = y + ky - center;\n",
        "\n",
        "                sum += input[imageY * width + imageX] * kernel[ky * kernelSize + kx];\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // set the output pixel value\n",
        "        output[y * width + x] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "// function to apply Laplacian of Gaussian (LoG) filter using CUDA with shared memory\n",
        "void applyLoGFilterCUDA(const float *input, float *output, int width, int height, int blockDimX, int blockDimY,\n",
        "                            int gridDimX, int gridDimY, int gridDimZ, int dim, float& milliseconds) {\n",
        "    // define the Laplacian of Gaussian (LoG) kernel\n",
        "    float kernel[9] = {\n",
        "        0, 1, 0,\n",
        "        1, -4, 1,\n",
        "        0, 1, 0\n",
        "    };\n",
        "    int kernelSize = 3;\n",
        "\n",
        "    // // define 5x5 kernel\n",
        "    // float kernel[25] = {\n",
        "    //     0, 0, 1, 0, 0,\n",
        "    //     0, 1, 2, 1, 0,\n",
        "    //     1, 2, -16, 2, 1,\n",
        "    //     0, 1, 2, 1, 0,\n",
        "    //     0, 0, 1, 0, 0\n",
        "    // };\n",
        "    // int kernelSize = 5;\n",
        "\n",
        "    int threadsPerBlock = blockDimX * blockDimY;\n",
        "    if (threadsPerBlock > 1024) {\n",
        "        std::cerr << \"Error: The number of threads per block must be less than or equal to 1024.\" << std::endl;\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    // allocate device memory\n",
        "    float *d_input, *d_output, *d_kernel;\n",
        "    gpuErrchk(cudaMalloc((void**)&d_input, width * height * sizeof(float)));\n",
        "    gpuErrchk(cudaMalloc((void**)&d_output, width * height * sizeof(float)));\n",
        "    gpuErrchk(cudaMalloc((void**)&d_kernel, kernelSize * kernelSize * sizeof(float)));\n",
        "\n",
        "    // copy data from host to device\n",
        "    gpuErrchk(cudaMemcpy(d_input, input, width * height * sizeof(float), cudaMemcpyHostToDevice));\n",
        "    gpuErrchk(cudaMemcpy(d_kernel, kernel, kernelSize * kernelSize * sizeof(float), cudaMemcpyHostToDevice));\n",
        "\n",
        "    // configure and launch the CUDA kernel with shared memory\n",
        "    dim3 blockDim(blockDimX, blockDimY);\n",
        "    dim3 gridDim(gridDimX, gridDimY, gridDimZ);\n",
        "\n",
        "    // warmup kernel\n",
        "    int *dummy;\n",
        "    cudaMalloc((void**)&dummy, width * height * sizeof(int));\n",
        "    warmupKernel<<<gridDim, blockDim>>>(dummy);\n",
        "    cudaFree(dummy);\n",
        "\n",
        "    // create cuda event for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // print number of thread in each block\n",
        "    std::cout << \"blockDimX: \" << blockDimX << std::endl;\n",
        "    std::cout << \"blockDimY: \" << blockDimY << std::endl;\n",
        "    std::cout << \"gridDimX: \" << gridDimX << std::endl;\n",
        "    std::cout << \"gridDimY: \" << gridDimY << std::endl;\n",
        "    std::cout << \"gridDimZ: \" << gridDimZ << std::endl;\n",
        "    std::cout << \"number of threads in each block: \" << blockDimX * blockDimY << std::endl;\n",
        "    std::cout << \"total number of blocks: \" << gridDimX * gridDimY * gridDimZ << std::endl;\n",
        "    std::cout << \"total number of threads: \" << gridDimX * gridDimY * gridDimZ * blockDimX * blockDimY << std::endl;\n",
        "\n",
        "    // start timing\n",
        "    cudaEventRecord(start);\n",
        "    convolutionKernel<<<gridDim, blockDim>>>(d_input, d_output, width, height, d_kernel, kernelSize);\n",
        "    gpuErrchk(cudaPeekAtLastError());\n",
        "    gpuErrchk(cudaDeviceSynchronize());\n",
        "\n",
        "    // stop timing\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "    milliseconds = 0.0f;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    std::cout << \"time taken: \" << milliseconds << \" ms\" << std::endl;\n",
        "\n",
        "    // copy the result back to the host\n",
        "    cudaMemcpy(output, d_output, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // free device memory\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "    cudaFree(d_kernel);\n",
        "}\n",
        "\n",
        "void configure_grid_2D(int width, int height, const int& blockDimX, const int& blockDimY, int& gridDimX, int& gridDimY, int& gridDimZ) {\n",
        "    gridDimX = (width + blockDimX - 1) / blockDimX;\n",
        "    gridDimY = (height + blockDimY - 1) / blockDimY;\n",
        "    gridDimZ = 1;\n",
        "}\n",
        "\n",
        "void saveOutputImagePNG(const float *outputImage, int width, int height, const std::string& filename) {\n",
        "    // create output image buffer\n",
        "    unsigned char *outputImageChar = new unsigned char[width * height];\n",
        "\n",
        "    // convert output to unsigned char\n",
        "    for (int i = 0; i < width * height; ++i) {\n",
        "        outputImageChar[i] = (unsigned char) std::round(outputImage[i] * 255.0f);\n",
        "    }\n",
        "\n",
        "    // save the output image\n",
        "    stbi_write_png(filename.c_str(), width, height, 1, outputImageChar, 0);\n",
        "\n",
        "    delete[] outputImageChar;\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]) {\n",
        "\n",
        "    // ./program <input_image> <output_image> | ./program <input_image> <output_image> <-test>\n",
        "    if (argc != 3 && argc != 4) {\n",
        "        std::cerr << \"Usage: \" << argv[0] << \" input_image output_image\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "    else if (argc == 4 && std::string(argv[3]) != \"-test\") {\n",
        "        std::cerr << \"Usage: \" << argv[0] << \" input_image output_image\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    if (argc == 4) {\n",
        "        std::cout << \"Running in test mode.\" << std::endl;\n",
        "        TEST_MODE = true;\n",
        "    }\n",
        "\n",
        "    // load input image\n",
        "    int width, height, channels;\n",
        "    unsigned char *inputImage = stbi_load(argv[1], &width, &height, &channels, 1);\n",
        "    float *outputImageFloat = new float[width * height];\n",
        "\n",
        "    if (!inputImage) {\n",
        "        std::cerr << \"Error loading image: \" << stbi_failure_reason() << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // print width and height\n",
        "    std::cout << \"width: \" << width << std::endl;\n",
        "    std::cout << \"height: \" << height << std::endl;\n",
        "\n",
        "    // convert input to float\n",
        "    float *inputImageFloat = new float[width * height];\n",
        "    for (int i = 0; i < width * height; ++i) {\n",
        "        inputImageFloat[i] = inputImage[i] / 255.0f;\n",
        "    }\n",
        "\n",
        "  if (TEST_MODE) {\n",
        "        int blockDimX;\n",
        "        int blockDimY;\n",
        "        int gridDimX, gridDimY, gridDimZ;\n",
        "        float milliseconds = 0.0f;\n",
        "\n",
        "        int fixedDimensionsX[9] = {32, 64, 128, 256, 512, 1024, 8, 16, 32};\n",
        "        int fixedDimensionsY[9] = {1, 1, 1, 1, 1, 1, 8, 16, 32};\n",
        "        int numFixedDimensions = 9;\n",
        "\n",
        "        // block combination array ex: 1 row as 1 block, 2 rows as 1 block, etc.\n",
        "        int blockDimXArray[6] = {width, width / 2, width / 4, width/2, width/4, 1};\n",
        "        int blockDimYArray[6] = {1, 1, 1, 2, 4, height};\n",
        "        int numBlockCombinations = 6;\n",
        "\n",
        "        // test fixed dimensions\n",
        "        for (int i = 0; i < numFixedDimensions; ++i) {\n",
        "            blockDimX = fixedDimensionsX[i];\n",
        "            blockDimY = fixedDimensionsY[i];\n",
        "            std::cout << std::endl << std::endl;\n",
        "\n",
        "            configure_grid_2D(width, height, blockDimX, blockDimY, gridDimX, gridDimY, gridDimZ);\n",
        "            std::string filename = \"output_2D_\" + std::to_string(blockDimX) + \"_\" + std::to_string(blockDimY) + \".png\";\n",
        "            applyLoGFilterCUDA(inputImageFloat, outputImageFloat, width, height, blockDimX, blockDimY, gridDimX, gridDimY, gridDimZ, 2, milliseconds);\n",
        "            saveOutputImagePNG(outputImageFloat, width, height, filename);\n",
        "        }\n",
        "\n",
        "        // test configurable dimensions\n",
        "        for (int i = 0; i < numBlockCombinations; ++i) {\n",
        "            blockDimX = blockDimXArray[i];\n",
        "            blockDimY = blockDimYArray[i];\n",
        "            std::cout << std::endl << std::endl;\n",
        "\n",
        "            configure_grid_2D(width, height, blockDimX, blockDimY, gridDimX, gridDimY, gridDimZ);\n",
        "\n",
        "            applyLoGFilterCUDA(inputImageFloat, outputImageFloat, width, height, blockDimX, blockDimY, gridDimX, gridDimY, gridDimZ, 2, milliseconds);\n",
        "            std::string filename = \"output_2D_\" + std::to_string(blockDimX) + \"_\" + std::to_string(blockDimY) + \".png\";\n",
        "            saveOutputImagePNG(outputImageFloat, width, height, filename);\n",
        "        }\n",
        "        return 0;\n",
        "    }\n",
        "\n",
        "\n",
        "    // apply Laplacian of Gaussian (LoG) filter using CUDA with shared memory\n",
        "\n",
        "    // one block per row\n",
        "    int blockDimX = width;\n",
        "    int blockDimY = 1;\n",
        "    int gridDimX, gridDimY, gridDimZ;\n",
        "\n",
        "    configure_grid_2D(width, height, blockDimX, blockDimY, gridDimX, gridDimY, gridDimZ);\n",
        "\n",
        "    float sum = 0.0f;\n",
        "    float milliseconds = 0.0f;\n",
        "    int count = 0;\n",
        "\n",
        "    for (int i = 0; i < 10; ++i) {\n",
        "        applyLoGFilterCUDA(inputImageFloat, outputImageFloat, width, height, blockDimX, blockDimY, gridDimX, gridDimY, gridDimZ, 2, milliseconds);\n",
        "        if (milliseconds != -1.0f) {\n",
        "            ++count;\n",
        "            sum += milliseconds;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    std::cout << \"average time taken: \" << sum / count << \" ms\" << std::endl;\n",
        "\n",
        "    saveOutputImagePNG(outputImageFloat, width, height, argv[2]);\n",
        "\n",
        "    // clean up\n",
        "    stbi_image_free(inputImage);\n",
        "    delete[] outputImageFloat;\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "id": "kbUHs9MLU5Q9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "896de809-1ebb-439e-afa8-f8cddc3dfaee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/convolution_without_shm.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -o \"/content/src/convolution_without_shm.o\" /content/src/convolution_without_shm.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0rdv7M-WxmE",
        "outputId": "4b54bf19-ec13-40ce-fe00-41af00d9aec2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(4275)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"old_limit\"\u001b[0m was set but never used\n",
            "     unsigned int cur, limit, old_limit;\n",
            "                              ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(5182)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"idata_limit_old\"\u001b[0m was set but never used\n",
            "                 stbi__uint32 idata_limit_old = idata_limit;\n",
            "                              ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(6969)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"out_size\"\u001b[0m was set but never used\n",
            "        int out_size = 0;\n",
            "            ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(6970)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"delays_size\"\u001b[0m was set but never used\n",
            "        int delays_size = 0;\n",
            "            ^\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/convolution_without_shm.o /content/src/image_03.png /content/src/conv_03_2.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtMjgot4W4FX",
        "outputId": "169b1928-f8b1-49cf-ce91-8066dc0b6e09"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "width: 933\n",
            "height: 882\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.13072 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.10448 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.104608 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.10608 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.104384 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.104832 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.10464 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.107936 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.108544 ms\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.104224 ms\n",
            "average time taken: 0.108045 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/convolution_without_shm.o /content/src/image_03.png /content/src/conv_03_2.png -test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQvq3osHynpQ",
        "outputId": "c8564e65-b798-4a72-ed9f-de88c990810d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in test mode.\n",
            "width: 933\n",
            "height: 882\n",
            "\n",
            "\n",
            "blockDimX: 32\n",
            "blockDimY: 1\n",
            "gridDimX: 30\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 32\n",
            "total number of blocks: 26460\n",
            "total number of threads: 846720\n",
            "time taken: 0.176704 ms\n",
            "\n",
            "\n",
            "blockDimX: 64\n",
            "blockDimY: 1\n",
            "gridDimX: 15\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 64\n",
            "total number of blocks: 13230\n",
            "total number of threads: 846720\n",
            "time taken: 0.096256 ms\n",
            "\n",
            "\n",
            "blockDimX: 128\n",
            "blockDimY: 1\n",
            "gridDimX: 8\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 128\n",
            "total number of blocks: 7056\n",
            "total number of threads: 903168\n",
            "time taken: 0.114816 ms\n",
            "\n",
            "\n",
            "blockDimX: 256\n",
            "blockDimY: 1\n",
            "gridDimX: 4\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 256\n",
            "total number of blocks: 3528\n",
            "total number of threads: 903168\n",
            "time taken: 0.100352 ms\n",
            "\n",
            "\n",
            "blockDimX: 512\n",
            "blockDimY: 1\n",
            "gridDimX: 2\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 512\n",
            "total number of blocks: 1764\n",
            "total number of threads: 903168\n",
            "time taken: 0.102496 ms\n",
            "\n",
            "\n",
            "blockDimX: 1024\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 1024\n",
            "total number of blocks: 882\n",
            "total number of threads: 903168\n",
            "time taken: 0.108928 ms\n",
            "\n",
            "\n",
            "blockDimX: 8\n",
            "blockDimY: 8\n",
            "gridDimX: 117\n",
            "gridDimY: 111\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 64\n",
            "total number of blocks: 12987\n",
            "total number of threads: 831168\n",
            "time taken: 0.129024 ms\n",
            "\n",
            "\n",
            "blockDimX: 16\n",
            "blockDimY: 16\n",
            "gridDimX: 59\n",
            "gridDimY: 56\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 256\n",
            "total number of blocks: 3304\n",
            "total number of threads: 845824\n",
            "time taken: 0.109728 ms\n",
            "\n",
            "\n",
            "blockDimX: 32\n",
            "blockDimY: 32\n",
            "gridDimX: 30\n",
            "gridDimY: 28\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 1024\n",
            "total number of blocks: 840\n",
            "total number of threads: 860160\n",
            "time taken: 0.117088 ms\n",
            "\n",
            "\n",
            "blockDimX: 933\n",
            "blockDimY: 1\n",
            "gridDimX: 1\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 933\n",
            "total number of blocks: 882\n",
            "total number of threads: 822906\n",
            "time taken: 0.107264 ms\n",
            "\n",
            "\n",
            "blockDimX: 466\n",
            "blockDimY: 1\n",
            "gridDimX: 3\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 466\n",
            "total number of blocks: 2646\n",
            "total number of threads: 1233036\n",
            "time taken: 0.108512 ms\n",
            "\n",
            "\n",
            "blockDimX: 233\n",
            "blockDimY: 1\n",
            "gridDimX: 5\n",
            "gridDimY: 882\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 233\n",
            "total number of blocks: 4410\n",
            "total number of threads: 1027530\n",
            "time taken: 0.103872 ms\n",
            "\n",
            "\n",
            "blockDimX: 466\n",
            "blockDimY: 2\n",
            "gridDimX: 3\n",
            "gridDimY: 441\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 932\n",
            "total number of blocks: 1323\n",
            "total number of threads: 1233036\n",
            "time taken: 0.112544 ms\n",
            "\n",
            "\n",
            "blockDimX: 233\n",
            "blockDimY: 4\n",
            "gridDimX: 5\n",
            "gridDimY: 221\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 932\n",
            "total number of blocks: 1105\n",
            "total number of threads: 1029860\n",
            "time taken: 0.110368 ms\n",
            "\n",
            "\n",
            "blockDimX: 1\n",
            "blockDimY: 882\n",
            "gridDimX: 933\n",
            "gridDimY: 1\n",
            "gridDimZ: 1\n",
            "number of threads in each block: 882\n",
            "total number of blocks: 933\n",
            "total number of threads: 822906\n",
            "time taken: 0.682432 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name conv_shm.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <string>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define STB_IMAGE_IMPLEMENTATION\n",
        "#include \"stb_image.h\"\n",
        "\n",
        "#define STB_IMAGE_WRITE_IMPLEMENTATION\n",
        "#include \"stb_image_write.h\"\n",
        "\n",
        "bool TEST_MODE = false;\n",
        "\n",
        "// dummy kernel that does nothing\n",
        "__global__ void warmupKernel(int *dummy) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    dummy[i] = 0;\n",
        "}\n",
        "\n",
        "__global__ void convolutionKernelShared(const float *input, float *output, int width, int height, const float *kernel, int kernelSize) {\n",
        "\n",
        "    int iy = blockIdx.x + (kernelSize - 1) / 2;\n",
        "\n",
        "    int ix = threadIdx.x + (kernelSize - 1) / 2;\n",
        "\n",
        "    // center of kernel in both dimensions\n",
        "    int center = (kernelSize - 1) / 2;\n",
        "\n",
        "    int idx = iy * width + ix;\n",
        "\n",
        "    int threadId = threadIdx.x;\n",
        "    int K2 = kernelSize * kernelSize;\n",
        "\n",
        "    // shared memory for the kernel\n",
        "    extern __shared__ float sdata[];\n",
        "\n",
        "    // load kernel into shared memory\n",
        "    if (threadId < K2) {\n",
        "        sdata[threadId] = kernel[threadId];\n",
        "    }\n",
        "\n",
        "    __syncthreads();\n",
        "\n",
        "    float sum = 0.0;\n",
        "\n",
        "    // check if the thread is within the image\n",
        "    if (idx < width * height) {\n",
        "        for (int ki = 0; ki < kernelSize; ++ki) {\n",
        "            for (int kj = 0; kj < kernelSize; ++kj) {\n",
        "                int imageX = ix + kj - center;\n",
        "                int imageY = iy + ki - center;\n",
        "\n",
        "                sum += input[imageY * width + imageX] * sdata[ki * kernelSize + kj];\n",
        "            }\n",
        "        }\n",
        "\n",
        "        output[idx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void applyLoGFilterCUDA(const float *input, float *output, int width, int height, float& milliseconds) {\n",
        "    // define the  kernel\n",
        "    float kernel[9] = {\n",
        "        0, 1, 0,\n",
        "        1, -4, 1,\n",
        "        0, 1, 0\n",
        "    };\n",
        "    int kernelSize = 3;\n",
        "\n",
        "    // define 5x5 kernel\n",
        "    // float kernel[25] = {\n",
        "    //     0, 0, 1, 0, 0,\n",
        "    //     0, 1, 2, 1, 0,\n",
        "    //     1, 2, -16, 2, 1,\n",
        "    //     0, 1, 2, 1, 0,\n",
        "    //     0, 0, 1, 0, 0\n",
        "    // };\n",
        "    // int kernelSize = 5;\n",
        "\n",
        "\n",
        "    // allocate device memory\n",
        "    float *d_input, *d_output, *d_kernel;\n",
        "    cudaMalloc((void**)&d_input, width * height * sizeof(float));\n",
        "    cudaMalloc((void**)&d_output, width * height * sizeof(float));\n",
        "    cudaMalloc((void**)&d_kernel, kernelSize * kernelSize * sizeof(float));\n",
        "\n",
        "    // copy data from host to device\n",
        "    cudaMemcpy(d_input, input, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_kernel, kernel, kernelSize * kernelSize * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // configure and launch the CUDA kernel with shared memory\n",
        "    int numBlocks = height - kernelSize + 1;\n",
        "    int threadsPerBlock = width - kernelSize + 1;\n",
        "    std::cout << \"numBlocks: \" << numBlocks << std::endl;\n",
        "    std::cout << \"threadsPerBlock: \" << threadsPerBlock << std::endl;\n",
        "\n",
        "    // warmup kernel\n",
        "    int *dummy;\n",
        "    cudaMalloc((void**)&dummy, numBlocks * threadsPerBlock * sizeof(int));\n",
        "    warmupKernel<<<numBlocks, threadsPerBlock>>>(dummy);\n",
        "    cudaFree(dummy);\n",
        "\n",
        "    // create cuda event for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // start timing\n",
        "    cudaEventRecord(start);\n",
        "    convolutionKernelShared<<<numBlocks, threadsPerBlock, kernelSize * kernelSize * sizeof(float)>>>(d_input, d_output, width, height, d_kernel, kernelSize);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    // stop timing\n",
        "    cudaEventSynchronize(stop);\n",
        "    milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    std::cout << \"Time taken: \" << milliseconds << \" ms\" << std::endl;\n",
        "\n",
        "    // copy the result back to the host\n",
        "    cudaMemcpy(output, d_output, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // free device memory\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "    cudaFree(d_kernel);\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]) {\n",
        "\n",
        "    // ./program <input_image> <output_image> | ./program <input_image> <output_image> <-test>\n",
        "    if (argc != 3 && argc != 4) {\n",
        "        std::cerr << \"Usage: \" << argv[0] << \" input_image output_image\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // load input image\n",
        "    int width, height, channels;\n",
        "    unsigned char *inputImage = stbi_load(argv[1], &width, &height, &channels, 1);\n",
        "    float *outputImageFloat = new float[width * height];\n",
        "\n",
        "    if (!inputImage) {\n",
        "        std::cerr << \"Error loading image: \" << stbi_failure_reason() << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // print width and height\n",
        "    std::cout << \"width: \" << width << std::endl;\n",
        "    std::cout << \"height: \" << height << std::endl;\n",
        "\n",
        "    // convert input to float\n",
        "    float *inputImageFloat = new float[width * height];\n",
        "    for (int i = 0; i < width * height; ++i) {\n",
        "        inputImageFloat[i] = inputImage[i] / 255.0f;\n",
        "    }\n",
        "\n",
        "    float sum = 0.0f;\n",
        "    float milliseconds = 0.0f;\n",
        "    for (int i = 0; i < 10; ++i) {\n",
        "        // apply Laplacian of Gaussian (LoG) filter using CUDA with shared memory\n",
        "        applyLoGFilterCUDA(inputImageFloat, outputImageFloat, width, height, milliseconds);\n",
        "        sum += milliseconds;\n",
        "    }\n",
        "    milliseconds = sum / 10.0f;\n",
        "    std::cout << \"Average time taken: \" << milliseconds << \" ms\" << std::endl;\n",
        "\n",
        "    // apply Laplacian of Gaussian (LoG) filter using CUDA with shared memory\n",
        "    // applyLoGFilterCUDA(inputImageFloat, outputImageFloat, width, height, milliseconds);\n",
        "\n",
        "    // create output image buffer\n",
        "    unsigned char *outputImage = new unsigned char[width * height];\n",
        "\n",
        "    // convert output to unsigned char\n",
        "    for (int i = 0; i < width * height; ++i) {\n",
        "        outputImage[i] = (unsigned char) std::round(outputImageFloat[i] * 255.0f);\n",
        "    }\n",
        "\n",
        "    // save the output image\n",
        "    stbi_write_png(argv[2], width, height, 1, outputImage, 0);\n",
        "\n",
        "    // clean up\n",
        "    stbi_image_free(inputImage);\n",
        "    delete[] outputImage;\n",
        "    delete[] outputImageFloat;\n",
        "\n",
        "    std::cout << \"Laplacian of Gaussian (LoG) edge detection completed successfully.\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OWdzbKjO2BUX",
        "outputId": "108e7146-e430-4151-b3eb-5ed7303baff1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/conv_shm.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -o \"/content/src/conv_shm.o\" /content/src/conv_shm.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFGPc4VO4PHW",
        "outputId": "ca3b8432-e77c-4d2f-8fad-1b09de12f5d3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(4275)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"old_limit\"\u001b[0m was set but never used\n",
            "     unsigned int cur, limit, old_limit;\n",
            "                              ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(5182)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"idata_limit_old\"\u001b[0m was set but never used\n",
            "                 stbi__uint32 idata_limit_old = idata_limit;\n",
            "                              ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(6969)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"out_size\"\u001b[0m was set but never used\n",
            "        int out_size = 0;\n",
            "            ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(6970)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"delays_size\"\u001b[0m was set but never used\n",
            "        int delays_size = 0;\n",
            "            ^\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/conv_shm.o /content/src/image_03.png /content/src/conv_03_3.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsgVCdaM4C-Z",
        "outputId": "71870a98-5c00-4d3c-f90a-81fdafdbc804"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "width: 933\n",
            "height: 882\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.110592 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.096288 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.097216 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.098304 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.0992 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.102144 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.101248 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.098336 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.098112 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.097856 ms\n",
            "Average time taken: 0.0999296 ms\n",
            "Laplacian of Gaussian (LoG) edge detection completed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda --name conv_without_sh.cu\n",
        "\n",
        "\n",
        "#include <iostream>\n",
        "#include <string>\n",
        "#include <cuda_runtime.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "#define STB_IMAGE_IMPLEMENTATION\n",
        "#include \"stb_image.h\"\n",
        "\n",
        "#define STB_IMAGE_WRITE_IMPLEMENTATION\n",
        "#include \"stb_image_write.h\"\n",
        "\n",
        "bool TEST_MODE = false;\n",
        "\n",
        "\n",
        "// dummy kernel that does nothing\n",
        "__global__ void warmupKernel(int *dummy) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    dummy[i] = 0;\n",
        "}\n",
        "\n",
        "__global__ void convolutionKernelShared(const float *input, float *output, int width, int height, const float *kernel, int kernelSize) {\n",
        "\n",
        "    // each block is assigned to a row of an image, iy integer index of y\n",
        "    int iy = blockIdx.x + (kernelSize - 1) / 2;\n",
        "\n",
        "    // each thread is assigned to a pixel in a row, ix integer index of x\n",
        "    int ix = threadIdx.x + (kernelSize - 1) / 2;\n",
        "\n",
        "    // center of kernel in both dimensions\n",
        "    int center = (kernelSize - 1) / 2;\n",
        "\n",
        "    int idx = iy * width + ix;\n",
        "\n",
        "    float sum = 0.0;\n",
        "    // check if the thread is within the image\n",
        "    if (idx < width * height) {\n",
        "        for (int ki = 0; ki < kernelSize; ++ki) {\n",
        "            for (int kj = 0; kj < kernelSize; ++kj) {\n",
        "                int imageX = ix + kj - center;\n",
        "                int imageY = iy + ki - center;\n",
        "\n",
        "                sum += input[imageY * width + imageX] * kernel[ki * kernelSize + kj];\n",
        "            }\n",
        "        }\n",
        "\n",
        "        output[idx] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "void applyLoGFilterCUDA(const float *input, float *output, int width, int height, float& milliseconds) {\n",
        "    // define the kernel\n",
        "    float kernel[9] = {\n",
        "        0, 1, 0,\n",
        "        1, -4, 1,\n",
        "        0, 1, 0\n",
        "    };\n",
        "\n",
        "    // allocate device memory\n",
        "    float *d_input, *d_output, *d_kernel;\n",
        "    cudaMalloc((void**)&d_input, width * height * sizeof(float));\n",
        "    cudaMalloc((void**)&d_output, width * height * sizeof(float));\n",
        "    cudaMalloc((void**)&d_kernel, 9 * sizeof(float));\n",
        "\n",
        "    // copy data from host to device\n",
        "    cudaMemcpy(d_input, input, width * height * sizeof(float), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_kernel, kernel, 9 * sizeof(float), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // configure and launch the CUDA kernel with shared memory\n",
        "    int kernelSize = 3;\n",
        "    int numBlocks = height - kernelSize + 1;\n",
        "    int threadsPerBlock = width - kernelSize + 1;\n",
        "    std::cout << \"numBlocks: \" << numBlocks << std::endl;\n",
        "    std::cout << \"threadsPerBlock: \" << threadsPerBlock << std::endl;\n",
        "\n",
        "    // create cuda event for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // start timing\n",
        "    cudaEventRecord(start);\n",
        "    convolutionKernelShared<<<numBlocks, threadsPerBlock, kernelSize * kernelSize * sizeof(float)>>>(d_input, d_output, width, height, d_kernel, kernelSize);\n",
        "    cudaEventRecord(stop);\n",
        "\n",
        "    // stop timing\n",
        "    cudaEventSynchronize(stop);\n",
        "    milliseconds = 0.0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "    std::cout << \"Time taken: \" << milliseconds << \" ms\" << std::endl;\n",
        "\n",
        "    // copy the result back to the host\n",
        "    cudaMemcpy(output, d_output, width * height * sizeof(float), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // free device memory\n",
        "    cudaFree(d_input);\n",
        "    cudaFree(d_output);\n",
        "    cudaFree(d_kernel);\n",
        "}\n",
        "\n",
        "int main(int argc, char *argv[]) {\n",
        "\n",
        "    // ./program <input_image> <output_image> | ./program <input_image> <output_image> <-test>\n",
        "    if (argc != 3 && argc != 4) {\n",
        "        std::cerr << \"Usage: \" << argv[0] << \" input_image output_image\" << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // Load input image\n",
        "    int width, height, channels;\n",
        "    unsigned char *inputImage = stbi_load(argv[1], &width, &height, &channels, 1);\n",
        "    float *outputImageFloat = new float[width * height];\n",
        "\n",
        "    if (!inputImage) {\n",
        "        std::cerr << \"Error loading image: \" << stbi_failure_reason() << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    // print width and height\n",
        "    std::cout << \"width: \" << width << std::endl;\n",
        "    std::cout << \"height: \" << height << std::endl;\n",
        "\n",
        "    // convert input to float\n",
        "    float *inputImageFloat = new float[width * height];\n",
        "    for (int i = 0; i < width * height; ++i) {\n",
        "        inputImageFloat[i] = inputImage[i] / 255.0f;\n",
        "    }\n",
        "\n",
        "    float milliseconds = 0.0;\n",
        "    float sum = 0.0;\n",
        "\n",
        "    for (int i = 0; i < 10; ++i) {\n",
        "        // apply Laplacian of Gaussian (LoG) filter using CUDA with shared memory\n",
        "        applyLoGFilterCUDA(inputImageFloat, outputImageFloat, width, height, milliseconds);\n",
        "        sum += milliseconds;\n",
        "    }\n",
        "\n",
        "    std::cout << \"Average time taken: \" << sum / 10.0 << \" ms\" << std::endl;\n",
        "\n",
        "    // create output image buffer\n",
        "    unsigned char *outputImage = new unsigned char[width * height];\n",
        "\n",
        "    // convert output to unsigned char\n",
        "    for (int i = 0; i < width * height; ++i) {\n",
        "        outputImage[i] = (unsigned char) std::round(outputImageFloat[i] * 255.0f);\n",
        "    }\n",
        "\n",
        "    // save the output image\n",
        "    stbi_write_png(argv[2], width, height, 1, outputImage, 0);\n",
        "\n",
        "    // clean up\n",
        "    stbi_image_free(inputImage);\n",
        "    delete[] outputImage;\n",
        "    delete[] outputImageFloat;\n",
        "\n",
        "    std::cout << \"Laplacian of Gaussian (LoG) edge detection completed successfully.\" << std::endl;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KzDzJCXl4Y0s",
        "outputId": "f3eceda9-8a14-4086-e8b5-52de48962072"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'File written in /content/src/conv_without_sh.cu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 -o \"/content/src/conv_without_sh.o\" /content/src/conv_without_sh.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5FRpWiE5tQj",
        "outputId": "3bb02e63-10b2-4fea-b21a-8bfddddc400d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(4275)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"old_limit\"\u001b[0m was set but never used\n",
            "     unsigned int cur, limit, old_limit;\n",
            "                              ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(5182)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"idata_limit_old\"\u001b[0m was set but never used\n",
            "                 stbi__uint32 idata_limit_old = idata_limit;\n",
            "                              ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(6969)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"out_size\"\u001b[0m was set but never used\n",
            "        int out_size = 0;\n",
            "            ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m/content/src/stb_image.h(6970)\u001b[0m: \u001b[01;35mwarning\u001b[0m #550-D: variable \u001b[01m\"delays_size\"\u001b[0m was set but never used\n",
            "        int delays_size = 0;\n",
            "            ^\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/src/conv_without_sh.o /content/src/image_03.png /content/src/conv_03_3.png"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3o5EoEFG54VR",
        "outputId": "1953d684-2c78-4a8a-c170-4079c0a224f0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "width: 933\n",
            "height: 882\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.21136 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.099744 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.099904 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.098304 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.097728 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.097984 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.098304 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.108448 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.098208 ms\n",
            "numBlocks: 880\n",
            "threadsPerBlock: 931\n",
            "Time taken: 0.098304 ms\n",
            "Average time taken: 0.110829 ms\n",
            "Laplacian of Gaussian (LoG) edge detection completed successfully.\n"
          ]
        }
      ]
    }
  ]
}